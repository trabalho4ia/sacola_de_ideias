"""
Vers√£o comentada e explicativa do backend/app.py
Use este arquivo para aprender como funciona a IA!
"""

# ============================================
# PARTE 1: CONFIGURA√á√ÉO DO MODELO DE EMBEDDINGS
# ============================================

from langchain_openai import OpenAIEmbeddings

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
embeddings_model = None  # Vari√°vel global para armazenar o modelo (singleton)

def get_embeddings_model():
    """
    Obt√©m o modelo de embeddings (padr√£o Singleton).
    
    Singleton = cria uma vez e reutiliza (economiza mem√≥ria e tempo).
    
    Por que Singleton?
    - Criar o modelo √© caro (precisa carregar na mem√≥ria)
    - N√£o precisa criar toda vez que chamar
    - Reutiliza o mesmo modelo para todas as requisi√ß√µes
    """
    global embeddings_model
    
    # Se ainda n√£o criou e tem API Key, cria agora
    if embeddings_model is None and OPENAI_API_KEY:
        # AQUI EST√Å A M√ÅGICA! Cria o modelo da OpenAI
        embeddings_model = OpenAIEmbeddings(
            openai_api_key=OPENAI_API_KEY,  # Sua chave da OpenAI (do .env)
            model="text-embedding-3-small"   # Modelo: pequeno = r√°pido e barato
            # Outros modelos dispon√≠veis:
            # - "text-embedding-3-large" (mais preciso, mais caro)
            # - "text-embedding-ada-002" (antigo, ainda funciona)
        )
    
    return embeddings_model  # Retorna o modelo (criado ou j√° existente)


def gerar_embedding(texto: str):
    """
    Transforma um texto em um vetor de n√∫meros (embedding).
    
    O que acontece:
    1. Pega o texto: "comprar leite"
    2. Envia para a API da OpenAI
    3. OpenAI usa uma rede neural (treinada em milh√µes de textos)
    4. A rede "entende" o significado do texto
    5. Transforma em 1536 n√∫meros que representam esse significado
    6. Retorna: [0.023, -0.045, 0.123, ..., 0.089]
    
    Cada n√∫mero no vetor captura algum aspecto do texto:
    - Alguns n√∫meros = t√≥pico (compras, trabalho, etc)
    - Alguns n√∫meros = sentimento (positivo, negativo)
    - Alguns n√∫meros = contexto (formal, informal)
    - etc...
    
    Por que 1536 n√∫meros?
    - √â o tamanho fixo do modelo text-embedding-3-small
    - Mais n√∫meros = mais informa√ß√£o capturada
    - Mas tamb√©m = mais caro e mais lento
    """
    # Passo 1: Pegar o modelo (ou criar se for primeira vez)
    model = get_embeddings_model()
    
    # Passo 2: Se n√£o tiver modelo (sem API Key), retorna None
    if not model:
        return None
    
    try:
        # Passo 3: AQUI ACONTECE A M√ÅGICA!
        # embed_query() = m√©todo que transforma texto em n√∫meros
        embedding = model.embed_query(texto)
        
        # embedding agora √© uma lista com 1536 n√∫meros:
        # [0.023, -0.045, 0.123, 0.456, ..., 0.089]
        
        # OP√á√ÉO: Descomente para ver os embeddings sendo gerados:
        # print(f"üîç Texto: '{texto}'")
        # print(f"üìä Embedding: {embedding[:5]}... (1536 n√∫meros no total)")
        
        return embedding
    except Exception as e:
        print(f"‚ùå Erro ao gerar embedding: {e}")
        return None


# ============================================
# PARTE 2: SALVAR IDEIA COM EMBEDDING
# ============================================

@app.post("/api/ideias")
def criar_ideia(ideia: IdeiaCreate):
    """
    Salva uma ideia e gera seu embedding automaticamente.
    
    Fluxo:
    1. Recebe t√≠tulo, tag e ideia
    2. Junta tudo em um texto
    3. Gera embedding (1536 n√∫meros)
    4. Salva no banco: texto + n√∫meros
    """
    conn = get_db_connection()
    try:
        embedding_str = None  # Vai armazenar embedding como string
        
        # Passo 1: Pegar modelo (se tiver API Key configurada)
        modelo = get_embeddings_model()
        
        if modelo:
            try:
                # Passo 2: Juntar tudo em um texto
                texto_completo = f"{ideia.titulo} {ideia.tag or ''} {ideia.ideia}".strip()
                # Exemplo: "Comprar leite trabalho lembretes do mercado"
                
                # Passo 3: GERAR EMBEDDING (TEXTO ‚Üí N√öMEROS)
                embedding = gerar_embedding(texto_completo)
                # embedding = [0.023, -0.045, ..., 0.089] (1536 n√∫meros)
                
                if embedding:
                    # Passo 4: Converter lista Python para string SQL
                    # PostgreSQL precisa receber como string formatada
                    embedding_str = "[" + ",".join(map(str, embedding)) + "]"
                    # Resultado: "[0.023,-0.045,0.123,...,0.089]"
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao gerar embedding (salvando sem embedding): {e}")
                # Se der erro, continua salvando sem embedding
                # A busca simples ainda vai funcionar
        
        # Passo 5: Salvar no banco
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if embedding_str:
                # Salvar COM embedding (pode fazer busca sem√¢ntica depois)
                cur.execute(
                    "INSERT INTO ideias (titulo, tag, ideia, embedding) VALUES (%s, %s, %s, %s::vector) RETURNING *",
                    (ideia.titulo, ideia.tag, ideia.ideia, embedding_str)
                    # %s::vector = converte string para tipo vector do PostgreSQL
                )
            else:
                # Salvar SEM embedding (s√≥ busca simples funciona)
                cur.execute(
                    "INSERT INTO ideias (titulo, tag, ideia) VALUES (%s, %s, %s) RETURNING *",
                    (ideia.titulo, ideia.tag, ideia.ideia)
                )
            
            nova_ideia = cur.fetchone()
            conn.commit()
            return dict(nova_ideia)


# ============================================
# PARTE 3: BUSCA POR SIMILARIDADE (A M√ÅGICA!)
# ============================================

@app.post("/api/ideias/buscar")
def buscar_por_similaridade(busca: BuscaRequest):
    """
    Busca ideias usando similaridade sem√¢ntica (IA).
    
    Como funciona:
    1. Recebe termo de busca: "compras"
    2. Gera embedding da busca: [0.021, -0.043, ..., 0.087]
    3. Compara com todos embeddings salvos
    4. Calcula similaridade (0.0 a 1.0)
    5. Filtra e ordena por similaridade
    6. Retorna resultados com porcentagem
    """
    conn = get_db_connection()
    try:
        # Passo 1: Verificar se tem modelo (API Key configurada)
        modelo = get_embeddings_model()
        
        if not modelo:
            # FALLBACK: Se n√£o tiver API Key, faz busca simples (texto)
            # Busca usando LIKE (cont√©m o texto)
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                termo = busca.termo.lower()
                cur.execute("""
                    SELECT *, 0.0 AS similarity
                    FROM ideias
                    WHERE LOWER(titulo) LIKE %s 
                       OR LOWER(tag) LIKE %s 
                       OR LOWER(ideia) LIKE %s
                    ORDER BY data DESC
                    LIMIT 20
                """, (f'%{termo}%', f'%{termo}%', f'%{termo}%'))
                return [dict(r) for r in cur.fetchall()]
        
        # Passo 2: GERAR EMBEDDING DA BUSCA
        # Usu√°rio busca "compras" ‚Üí vira [0.021, -0.043, ..., 0.087]
        embedding_busca = gerar_embedding(busca.termo)
        
        if not embedding_busca:
            raise HTTPException(status_code=500, detail="Erro ao gerar embedding da busca")
        
        # Passo 3: Converter para formato PostgreSQL
        embedding_str = "[" + ",".join(map(str, embedding_busca)) + "]"
        # Resultado: "[0.021,-0.043,0.123,...,0.087]"
        
        # Passo 4: BUSCAR NO BANCO USANDO pgvector
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT 
                    id,
                    titulo,
                    tag,
                    ideia,
                    data,
                    -- CALCULAR SIMILARIDADE:
                    -- <=> = operador de dist√¢ncia do pgvector
                    -- Calcula qu√£o "perto" est√£o dois vetores
                    -- Menor dist√¢ncia = mais similares
                    --
                    -- 1 - dist√¢ncia = converte dist√¢ncia em similaridade
                    -- Dist√¢ncia 0.0 (id√™nticos) ‚Üí Similaridade 1.0 (100%)
                    -- Dist√¢ncia 1.0 (muito diferentes) ‚Üí Similaridade 0.0 (0%)
                    1 - (embedding <=> %s::vector) AS similarity
                    
                FROM ideias
                
                -- S√≥ busca ideias que t√™m embedding (foram salvas com IA)
                WHERE embedding IS NOT NULL
                
                -- FILTRAR: S√≥ mostra resultados com 30%+ de similaridade
                -- Ajuste este valor:
                -- 0.2 = permissivo (mostra mais resultados)
                -- 0.3 = padr√£o (equil√≠brio)
                -- 0.5 = rigoroso (s√≥ muito similares)
                -- 0.7 = muito rigoroso (quase id√™nticos)
                AND (1 - (embedding <=> %s::vector)) >= 0.3
                
                -- ORDENAR: Do mais similar ao menos similar
                -- embedding <=> busca = dist√¢ncia
                -- Menor dist√¢ncia = mais similar = aparece primeiro
                ORDER BY embedding <=> %s::vector
                
                -- LIMITAR: M√°ximo 20 resultados
                LIMIT 20
            """, (embedding_str, embedding_str, embedding_str))
            # Nota: passa embedding_str 3 vezes (uma para cada %s)
            # Porque usa 3 vezes na query: SELECT, WHERE, ORDER BY
            
            resultados = cur.fetchall()
            return [dict(resultado) for resultado in resultados]
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na busca: {str(e)}")
    finally:
        conn.close()


# ============================================
# RESUMO: COMO FUNCIONA A M√ÅGICA
# ============================================

"""
FLUXO COMPLETO:

SALVAR:
Texto ‚Üí Embedding (1536 n√∫meros) ‚Üí Salva no banco

BUSCAR:
Termo ‚Üí Embedding (1536 n√∫meros) ‚Üí Compara com todos ‚Üí Retorna similares

POR QUE FUNCIONA:
- Textos similares geram vetores similares
- Comparar n√∫meros √© mais f√°cil que comparar textos
- Similaridade de cosseno mede "qu√£o parecidos" s√£o os vetores

EXEMPLO:
"comprar leite" e "ir √†s compras" t√™m vetores parecidos
"comprar leite" e "reuni√£o de trabalho" t√™m vetores diferentes
"""

